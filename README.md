# Crochet-MultiModal-LLMs
A multimodal LLM Research Repository.
Contributors : Hariansh Vashist | Divyansh goyal


Research Statement : 
### Hallucinations in Multimodal Large Language Models based on vectorsearch datasets. || Improving OCR capabilities in Large Vision Language Models (LVLM's)
the latter is what is our focus is on at the moment.
### Currently Exploring : Google Gemini Pro + DOCVQA 


Key terminologies:
### Ground truth in datasets 
### Multimodality
### Evaluation metric 

Compute:
### Azure machine learning studio (free credit accounts exist but they will require student ID's)

References : 
[https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models]Awesome MultiModal LLM's Large Language Models(github repo)
[https://huyenchip.com/2023/10/10/multimodal.html] Chip Huyen Multimodal LLM web research paper.


Research Paper to be published on over:
Arxiv
Google-Scholar
ResearchGate

Potential popular conferences:
IEEE
ICVPR
NeurIPS (important)

Helpful Platforms:
Huggingface, Medium (for documentation) / Hashnode / mem.ai / Notion, Github Projects
Todoist (for tracking progress)

